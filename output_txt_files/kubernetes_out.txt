<paste log output from Kubernetes-mediated prediction, here>

- Make_prediction output

$ sh make_prediction.sh
Port: 8080
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100   260  100    48  100   212    186    822 --:--:-- --:--:-- --:--:--  1007{
  "prediction": [
    20.35373177134412
  ]
}

- Log from pod

$ kubectl logs skpredict-api
 * Serving Flask app "app" (lazy loading)
 * Environment: production
   WARNING: Do not use the development server in a production environment.
   Use a production WSGI server instead.
 * Debug mode: on
 * Running on http://0.0.0.0:80/ (Press CTRL+C to quit)
 * Restarting with stat
 * Debugger is active!
 * Debugger PIN: 190-766-172
[2023-05-14 04:01:16,306] INFO in app: JSON payload:
{'CHAS': {'0': 0}, 'RM': {'0': 6.575}, 'TAX': {'0': 296.0}, 'PTRATIO': {'0': 15.3}, 'B': {'0': 396.9}, 'LSTAT': {'0': 4.98}}
[2023-05-14 04:01:16,339] INFO in app: Inference payload DataFrame:
   CHAS     RM    TAX  PTRATIO      B  LSTAT
0     0  6.575  296.0     15.3  396.9   4.98
[2023-05-14 04:01:16,361] INFO in app: Scaling Payload:
   CHAS     RM    TAX  PTRATIO      B  LSTAT
0     0  6.575  296.0     15.3  396.9   4.98
[2023-05-14 04:01:16,377] INFO in app: Prediction result: [20.35373177134412]
127.0.0.1 - - [14/May/2023 04:01:16] "POST /predict HTTP/1.1" 200 -


- Start kubernetes

$ sh run_kubernetes.sh
NAME            READY   STATUS    RESTARTS   AGE
skpredict-api   1/1     Running   0          13s
Forwarding from 127.0.0.1:8080 -> 80
Forwarding from [::1]:8080 -> 80
Handling connection for 8080
